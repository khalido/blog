<!DOCTYPE html>
<html>

    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link href="/tailwind.css" rel="stylesheet">

        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/styles/a11y-dark.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js"></script>

        <script defer src="https://unpkg.com/alpinejs@3.x.x/dist/cdn.min.js"></script>

        <title>Apache Spark</title>
    </head>

    <body class="bg-yellow-100">

        <header class="bg-yellow-400 p-4 sm:p-6 md:p-8 lg:p-10 xl:p-12">
            <a href="/" 
            class="text-3xl font-mono tracking-wider font-extrabold"
            >khalido.org</a>
            <br>
            <p>every blog needs subheader text</p>
        </header>

        <!--container setting paddings-->
        <div
    class="max-w-3xl
      mx-auto
      px-4 py-5
      sm:px-6 
      md:px-7 
      lg:max-w-4xl lg:px-8
      xl:max-w-5xl xl:px-9
      bg-gray-50"
      >
 
        


<article class="prose md:prose-lg lg:prose-xl">
    <h1 id=apache-spark>Apache Spark</h1>

    <details close class="fixed top-0 right-0 text-sm text-gray-500">
        <summary>Table of contents.</summary>
        <div class="toc">
<ul>
<li><a href="#apache-spark">Apache Spark</a><ul>
<li><a href="#rdd">RDD</a></li>
<li><a href="#map-all-the-things-to-something-else">map all the things to something else</a></li>
<li><a href="#install-spark-on-your-local-machine">install spark on your local machine</a></li>
</ul>
</li>
</ul>
</div>

    </details>
    
    
<p>Way back in the good old days Google came up with mapreduce to store and crunch data scattered on disks across multiple machines. The world looked at mapreduce and thought it good, and made an open source implementation called Hadoop.</p>
<p>Ppl wanted more, and faster, and luckily memory prices went down. And thus Apache Spark was born at UC Berkely. Spark stores data across a bunch of machines in memory. This makes it easy and fast to data scientist all the data.</p>
<h2 id="rdd">RDD</h2>
<p>The key buzzword here is RDD which stands for resilient distributed data set. Spark has a <code>SparkContext</code> object which manages the connection to clusters and how processes are run on those clusters. So we call it using code like <code>data = sc.textFile(``'``name_of_text_file.txt``'``)</code>. With text data, this just becomes a list of strings - one per each line in the text file which is accessed using <code>sc.take(num_of_lines)</code>.</p>
<p>Now, even though this looks very pythonic, don’t think of spark data objects which look like lists as lists. Python lists are meant to be run on a single machine, so they can be sliced and diced. Spark data is designed to be used across machines, so slices don’t make sense in that context.</p>
<p>RDD's are immutable - so to modify data stored inside it, we get back a new RDD. Python has both mutable objects - like lists and dictionaries - and immutable ones like tuples, so this isn't anything different from mainstream python.</p>
<h2 id="map-all-the-things-to-something-else">map all the things to something else</h2>
<p><code>map(func)</code> applies the function <code>func</code> to all the things in the RDD and returns a new RDD. so something like <code>data.map(lambda line: line.split('\t'))</code> applies the func passed into map to each object stored in the RDD and returns back a new RDD.</p>
<p><code>map</code> is often accompanies by <a href="https://spark.apache.org/docs/latest/rdd-programming-guide.html#ReduceByLink">reduceByKey</a> e.g to count stuff:</p>
<pre><code class="language-python">lines = sc.textFile(&quot;data.txt&quot;)
pairs = lines.map(lambda s: (s, 1))
counts = pairs.reduceByKey(lambda a, b: a + b)
</code></pre>
<p>Now, spark deals with transformations only when it has to - so it builds up a pipelines of tasks and runs them when the output of those tasks is called.</p>
<h2 id="install-spark-on-your-local-machine">install spark on your local machine</h2>
<p>Use Spark on a local machine is useful for learning purposes - for actual production use I would use <a href="https://aws.amazon.com/emr/">Amazon EMR</a> or <a href="https://cloud.google.com/dataproc/">Google Cloud Dataproc</a>.</p>
<p>Spark needs Java, so to install it properly it needs a lot of installation. So to avoid all that I'm using a <a href="https://docs.docker.com/get-started/">docker</a> image with spark preinstalled: <a href="http://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pyspark-notebook">jupyter/pyspark-notebook</a></p>
<p><code>docker run -d -P --name notebook jupyter/pyspark-notebook</code></p>
<p>Note: use <code>-v</code> to mount the current directory in the docker container.</p>

    <!-- post meta info div-->
    <div class="text-gray-600 text-base">
        posted <time>2016-01-01</time>, updated <time>2021-08-24</time><br>
        tagged: 
        <a href="/untagged"
        class="text-pink-500 bg-transparent hover:bg-pink-500 hover:text-white active:bg-pink-600 font-bold rounded outline-none focus:outline-none mr-1 mb-1 ease-linear transition-all duration-150">
        untagged</a>

            View on: <a href="https://github.com/khalido/blog/blob/master/posts/apache-spark.md"
            class="text-purple-500 hover:bg-purple-500 hover:text-white active:bg-purple-600 font-bold rounded outline-none focus:outline-none mr-1 mb-1 ease-linear transition-all duration-150">
            github</a>
    
    </div>
</article>

<script>hljs.highlightAll();</script>
</div> <!-- closes first div after body -->

<hr>
<footer class="px-4 py-8 content-center text-center">
    <p class="text-sm text-gray-300 pb-2">
        <a href="https://github.com/khalido/blog">#</a>
        <a href="https://twitter.com/KO">@ko</a>
    </p>
</footer>

</body>

</html>